distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
distributed.scheduler - INFO - Clear task state
distributed.scheduler - INFO -   Scheduler at:  tcp://10.128.5.132:34697
distributed.scheduler - INFO -   dashboard at:                     :8787
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:36835', name: 16, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:36835
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:38901
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:38901
distributed.worker - INFO -          dashboard at:         10.128.5.132:42255
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-za3jk034
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.132:38901', name: 11, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.132:38901
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:40633', name: 52, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:40633
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:34247', name: 25, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:34247
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:38711
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:38711
distributed.worker - INFO -          dashboard at:         10.128.5.132:42183
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-awpl6j_u
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.132:38711', name: 3, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.132:38711
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:36627', name: 47, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:36627
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:37791
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:37791
distributed.worker - INFO -          dashboard at:         10.128.5.132:35617
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-455t5ik8
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.132:37791', name: 5, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.132:37791
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:33775
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:33775
distributed.worker - INFO -          dashboard at:         10.128.5.132:35427
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-mrxgy1u6
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.132:33775', name: 14, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.132:33775
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:34935
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:34935
distributed.worker - INFO -          dashboard at:         10.128.5.134:40361
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.134:34935', name: 36, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.134:34935
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:35655
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:35655
distributed.worker - INFO -          dashboard at:         10.128.51.80:36395
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7g0v3sif
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:35655', name: 75, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:35655
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xjcyecjp
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:44281
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:44281
distributed.worker - INFO -          dashboard at:         10.128.5.133:35311
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b5qwlu_y
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.133:44281', name: 17, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.133:44281
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:43561
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:43561
distributed.worker - INFO -          dashboard at:         10.128.5.134:38363
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-00mqvvny
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.134:43561', name: 35, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.134:43561
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:38487
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:38487
distributed.worker - INFO -          dashboard at:         10.128.5.134:42509
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-80bu3h_i
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.134:38487', name: 50, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.134:38487
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:43685
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:43685
distributed.worker - INFO -          dashboard at:         10.128.5.134:38409
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0jeevpgs
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:44347
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:44347
distributed.worker - INFO -          dashboard at:         10.128.5.135:36483
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:45599
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:45599
distributed.worker - INFO -          dashboard at:         10.128.51.80:41761
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.134:43685', name: 49, memory: 0, processing: 0>
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2z_8vgco
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.134:43685
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:45599', name: 83, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:45599
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.135:44347', name: 58, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.135:44347
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:45775
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:45775
distributed.worker - INFO -          dashboard at:         10.128.51.80:36325
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-oy0wuj85
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:45815
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:45815
distributed.worker - INFO -          dashboard at:         10.128.51.80:37195
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-b3zf7t6s
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:45775', name: 72, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:45775
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:45327', name: 9, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:45327
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:45815', name: 80, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:45815
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:35315
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:35315
distributed.worker - INFO -          dashboard at:         10.128.5.132:42897
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-1_mx9cfs
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-lr0xaofe
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.132:35315', name: 13, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.132:35315
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:46713
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:46713
distributed.worker - INFO -          dashboard at:         10.128.51.80:41949
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-eyd3n12b
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:33707
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:36581
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:36581
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:33707
distributed.worker - INFO -          dashboard at:         10.128.5.133:38013
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -          dashboard at:         10.128.5.133:39787
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-udj10hov
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ruwsezbb
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:46713', name: 84, memory: 0, processing: 0>
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:41989
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:41989
distributed.worker - INFO -          dashboard at:         10.128.5.133:34871
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6hznz5xd
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:46713
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:43529
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:43529
distributed.worker - INFO -          dashboard at:         10.128.51.80:34753
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gt4ttzr4
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:43529', name: 81, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:43529
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:40491
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:40491
distributed.worker - INFO -          dashboard at:         10.128.51.80:43693
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9ja85t13
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:37849
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:37849
distributed.worker - INFO -          dashboard at:         10.128.51.80:41685
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-epu1q2we
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:40491', name: 82, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:40491
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:39143
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:39143
distributed.worker - INFO -          dashboard at:         10.128.51.80:42633
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-zvcqi__g
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.133:33707', name: 21, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.133:33707
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.133:41989', name: 27, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.133:41989
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:37849', name: 69, memory: 0, processing: 0>
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:38173
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:38173
distributed.worker - INFO -          dashboard at:         10.128.51.80:39801
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2v6e5pyi
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:37849
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.133:36581', name: 22, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.133:36581
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:39143', name: 73, memory: 0, processing: 0>
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:39143
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:33221
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:33221
distributed.worker - INFO -          dashboard at:         10.128.5.133:35159
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o2nif2h2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:45087
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:45087
distributed.worker - INFO -          dashboard at:         10.128.5.133:43253
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o18w7pp2
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:38081
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:38081
distributed.worker - INFO -          dashboard at:         10.128.51.80:38035
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-eys9epcj
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:38173', name: 78, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:38173
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.133:33221', name: 32, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.133:33221
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.133:45087', name: 20, memory: 0, processing: 0>
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.133:45087
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:38081', name: 74, memory: 0, processing: 0>
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:38081
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:40929
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:40929
distributed.worker - INFO -          dashboard at:         10.128.51.80:33065
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3qvf7a4h
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:40929', name: 76, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:40929
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:41837', name: 57, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:41837
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 36
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 73
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:34719
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:34719
distributed.worker - INFO -          dashboard at:         10.128.5.135:38567
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-w3csxmfs
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.135:34719', name: 66, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.135:34719
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 20
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:43705
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:43705
distributed.worker - INFO -          dashboard at:         10.128.51.80:40425
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5q6w389e
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:40969
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:35391
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:40969
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:35391
distributed.worker - INFO -          dashboard at:         10.128.51.80:41835
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -          dashboard at:         10.128.51.80:34047
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-p_v06lp6
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6ywpn50g
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:37675
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:37675
distributed.worker - INFO -          dashboard at:         10.128.51.80:46103
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0sw_ef92
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:43705', name: 77, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:43705
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:40969', name: 71, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:40969
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:37675', name: 79, memory: 0, processing: 0>
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:37675
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:35391', name: 68, memory: 0, processing: 0>
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:35391
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.51.80:42665
distributed.worker - INFO -          Listening to:   tcp://10.128.51.80:42665
distributed.worker - INFO -          dashboard at:         10.128.51.80:41623
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ie95f5yb
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.51.80:42665', name: 70, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.51.80:42665
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:36499', name: 1, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:36499
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 21
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:45913', name: 46, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:45913
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:37175', name: 2, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:37175
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 11
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:33821', name: 12, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:33821
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:36143', name: 8, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:36143
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:44289', name: 6, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:44289
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:40943', name: 4, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:40943
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 14
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 5
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:33761', name: 15, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:33761
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:39883', name: 7, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:39883
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.37:46447', name: 10, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.37:46447
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 13
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:42065
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:42065
distributed.worker - INFO -          dashboard at:         10.128.5.132:34221
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-g6tedbfp
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:44865
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:44865
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:39729
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.132:41109
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:39729
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:38059
distributed.worker - INFO -          dashboard at:         10.128.5.132:45509
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:43301
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:38059
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8j4lyca7
distributed.worker - INFO -          dashboard at:         10.128.5.132:39737
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:43301
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-nmx82m11
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.132:34925
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-dpks0h_y
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:37767
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:37767
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-iol94agl
distributed.worker - INFO -          dashboard at:         10.128.5.132:45189
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tproufob
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:39587
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:39587
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:33691
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:33709
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:33691
distributed.worker - INFO -          dashboard at:         10.128.5.132:33453
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:36723
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:33709
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.132:40643
distributed.worker - INFO -          dashboard at:         10.128.5.132:41437
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:36723
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -          dashboard at:         10.128.5.132:45049
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ji0cdjo5
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-opx6byq_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-0ydv0lze
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vrrhksu_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 2
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 7
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 6
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 4
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 2', 'time': 1640914685.5180218}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 8
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 7', 'time': 1640914685.5186305}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 16
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 9
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 6', 'time': 1640914685.5194094}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 4', 'time': 1640914685.5198781}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 12
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 10
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 8', 'time': 1640914685.5203376}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 1
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 16', 'time': 1640914685.5210814}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 9', 'time': 1640914685.5212467}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 12', 'time': 1640914685.5220594}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 10', 'time': 1640914685.5222645}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 1', 'time': 1640914685.5224237}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 3
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.132:45687
distributed.worker - INFO -          Listening to:   tcp://10.128.5.132:45687
distributed.worker - INFO -          dashboard at:         10.128.5.132:40983
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tmo6f5f5
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 72
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 15
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 15', 'time': 1640914685.5993295}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 74
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:34705
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:34705
distributed.worker - INFO -          dashboard at:         10.128.5.135:35599
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-xrpz6o3m
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.5.135:34705', name: 61, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.5.135:34705
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:33349', name: 37, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:33349
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 35
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:33905', name: 34, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:33905
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:35187', name: 41, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:35187
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:41189', name: 39, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:41189
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:46745', name: 38, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:46745
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:33319', name: 48, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:33319
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:43473', name: 40, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:43473
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:43059', name: 44, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:43059
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 49
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:38689', name: 42, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:38689
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:39307', name: 45, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:39307
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.39:37983', name: 43, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.39:37983
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:46391
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:46391
distributed.worker - INFO -          dashboard at:         10.128.5.134:46061
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5j4iu7f6
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 39
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 39', 'time': 1640914685.714807}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 78
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 50
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 22
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:39743', name: 29, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:39743
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:38513', name: 23, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:38513
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:40077
distributed.core - INFO - Starting established connection
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:44975
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:40077
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:44975
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:43961
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 17
distributed.worker - INFO -          dashboard at:         10.128.5.134:44939
distributed.worker - INFO -          dashboard at:         10.128.5.134:37967
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:43961
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -          dashboard at:         10.128.5.134:46545
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-089i1rmh
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:45003
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:45003
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7cf93q1_
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kutzw_ob
distributed.worker - INFO -          dashboard at:         10.128.5.134:42803
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:44187
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hw0u_736
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:44187
distributed.worker - INFO -          dashboard at:         10.128.5.134:44735
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:43657
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:39587
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:43657
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:39587
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-myvmi4_k
distributed.worker - INFO -          dashboard at:         10.128.5.134:40781
distributed.worker - INFO -          dashboard at:         10.128.5.134:41035
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:45759
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:45759
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5urexi05
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:         10.128.5.134:44535
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-2er1ioe5
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-to2mzlk9
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:39483
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:39483
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.134:32997
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:40853
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:40853
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l0hgmjo5
distributed.worker - INFO -          dashboard at:         10.128.5.134:34667
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-s_5k0fhy
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:36557
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:36557
distributed.worker - INFO -          dashboard at:         10.128.5.134:38323
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9w5qbrrv
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:46789', name: 56, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:46789
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:35369', name: 67, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:35369
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 66
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:46199', name: 63, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:46199
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 61
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:34903', name: 62, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:34903
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:35513', name: 51, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:35513
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:46421', name: 54, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:46421
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:46807', name: 53, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:46807
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:38639', name: 60, memory: 0, processing: 0>
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.134:35095
distributed.worker - INFO -          Listening to:   tcp://10.128.5.134:35095
distributed.worker - INFO -          dashboard at:         10.128.5.134:45305
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rakks1x_
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:38639
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:34657', name: 65, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:34657
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:45321', name: 64, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:45321
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:43813', name: 55, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:43813
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.40:43867', name: 59, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.40:43867
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:34381', name: 28, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:34381
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:43817', name: 24, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:43817
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 27
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:37935', name: 19, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:37935
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:34779', name: 30, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:34779
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:33457', name: 33, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:33457
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:44377', name: 18, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:44377
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 32
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:36301', name: 31, memory: 0, processing: 0>
distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:36301
distributed.core - INFO - Starting established connection
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 48
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 46
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 40
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 38
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 44
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 43
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 42
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 34
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 41
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 37
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 45
distributed.scheduler - INFO - Register worker <Worker 'tcp://10.128.8.38:36767', name: 26, memory: 0, processing: 0>
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 46', 'time': 1640914685.8343112}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 48', 'time': 1640914685.834104}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 40', 'time': 1640914685.8344617}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 38', 'time': 1640914685.834604}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 44', 'time': 1640914685.8348742}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.distributed.scheduler - INFO - Starting worker compute stream, tcp://10.128.8.38:36767
8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 43', 'time': 1640914685.83506}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.distributed.core - INFO - Starting established connection
8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 42', 'time': 1640914685.8352134}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 34', 'time': 1640914685.8353393}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 41', 'time': 1640914685.8354616}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 37', 'time': 1640914685.8355958}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 45', 'time': 1640914685.8357255}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 47
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 47', 'time': 1640914685.838792}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 58
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:39365
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:39365
distributed.worker - INFO -          dashboard at:         10.128.5.133:42115
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:41903
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kyogrjvz
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:41903
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.133:44697
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:38909
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:33833
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:33833
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:33259
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:38909
distributed.worker - INFO -          dashboard at:         10.128.5.133:37347
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:33259
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -          dashboard at:         10.128.5.133:37637
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-_s68ow1s
distributed.worker - INFO -          dashboard at:         10.128.5.133:43865
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-8qsjnqui
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-wm0j1qzx
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-tu9rthma
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:46375
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:46375
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:41949
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.133:35003
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:41949
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.133:39679
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-l6x7tvit
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:38411
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a5k4gb8w
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:38411
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:41655
distributed.worker - INFO -          dashboard at:         10.128.5.133:36957
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:41655
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.133:35251
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:38895
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3e6yvxi8
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:38895
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-f1njsgjf
distributed.worker - INFO -          dashboard at:         10.128.5.133:40515
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-a024cqyh
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 23
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 29
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 19
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 26
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 23', 'time': 1640914685.8644004}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 28
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 24
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 31
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 18
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 30
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 19', 'time': 1640914685.8655508}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 29', 'time': 1640914685.8653889}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 26', 'time': 1640914685.8656998}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 25
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 28', 'time': 1640914685.8667414}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 24', 'time': 1640914685.8669102}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 31', 'time': 1640914685.8670452}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 18', 'time': 1640914685.8671734}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 30', 'time': 1640914685.867298}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 25', 'time': 1640914685.8677504}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 81
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 77
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 82
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 69
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 79
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 71
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 68
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 84
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 83
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 70
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 80
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 75
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:45593
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:45593
distributed.worker - INFO -          dashboard at:         10.128.5.135:44743
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:38761
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:46321
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:46321
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:38761
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          dashboard at:         10.128.5.135:43321
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-ieoptvv2
distributed.worker - INFO -          dashboard at:         10.128.5.135:39833
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:43591
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:42965
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:42485
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:43591
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:42965
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:42485
distributed.worker - INFO -          dashboard at:         10.128.5.135:38689
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rdxhpq4c
distributed.worker - INFO -          dashboard at:         10.128.5.135:45063
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -          dashboard at:         10.128.5.135:39883
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:38883
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:38883
distributed.worker - INFO -          dashboard at:         10.128.5.135:44461
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:33361
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-3gjp0iv9
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-u2bjtmt1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-qdg65uk_
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:33361
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-6olq1ptu
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:36797
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.135:39057
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:36601
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:36797
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:44953
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4ce6oq3g
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:36601
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          dashboard at:         10.128.5.135:34725
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:44953
distributed.worker - INFO -          dashboard at:         10.128.5.135:43887
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-kdpmi55x
distributed.worker - INFO -          dashboard at:         10.128.5.135:35449
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-5u1vhboj
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-4cw8onhm
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-rolilc_f
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:33665
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:33665
distributed.worker - INFO -          dashboard at:         10.128.5.135:34997
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:46181
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:46181
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-vdqgcn9l
distributed.worker - INFO -          dashboard at:         10.128.5.135:32863
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-hmzti6g4
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 60
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.133:43595
distributed.worker - INFO -          Listening to:   tcp://10.128.5.133:43595
distributed.worker - INFO -          dashboard at:         10.128.5.133:37111
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-263s_65j
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 52
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 51
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 54
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 60', 'time': 1640914685.9376647}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 67
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 65
8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 52', 'time': 1640914685.9391956}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 59
8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 51', 'time': 1640914685.9393601}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 63
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 56
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 57
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 53
8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 54', 'time': 1640914685.9394956}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 55
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 62
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 67', 'time': 1640914685.9409552}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 59', 'time': 1640914685.941279}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 63', 'time': 1640914685.9414227}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 56', 'time': 1640914685.9415488}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 57', 'time': 1640914685.9416854}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 55', 'time': 1640914685.941935}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 65', 'time': 1640914685.9411356}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 53', 'time': 1640914685.941811}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 33
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 62', 'time': 1640914685.9420686}
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 33', 'time': 1640914685.945537}
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 76
distributed.worker - INFO -       Start worker at:   tcp://10.128.5.135:36743
distributed.worker - INFO -          Listening to:   tcp://10.128.5.135:36743
distributed.worker - INFO -          dashboard at:         10.128.5.135:39371
distributed.worker - INFO - Waiting to connect to:   tcp://10.128.5.132:34697
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          1
distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9qz7g5b9
distributed.worker - INFO - -------------------------------------------------
distributed.scheduler - WARNING - Worker tried to connect with a duplicate name: 64
Traceback (most recent call last):
  File "/opt/miniconda3/bin/dask-mpi", line 11, in <module>
    sys.exit(go())
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 112, in go
    main()
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/miniconda3/lib/python3.8/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 107, in main
    asyncio.get_event_loop().run_until_complete(run_worker())
  File "/opt/miniconda3/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/opt/miniconda3/lib/python3.8/site-packages/dask_mpi/cli.py", line 96, in run_worker
    async with WorkerType(
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 294, in __aenter__
    await self
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/core.py", line 284, in _
    await self.start()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 1166, in start
    await self._register_with_scheduler()
  File "/opt/miniconda3/lib/python3.8/site-packages/distributed/worker.py", line 914, in _register_with_scheduler
    raise ValueError("Unexpected response from register: %r" % (response,))
ValueError: Unexpected response from register: {'status': 'error', 'message': 'name taken, 64', 'time': 1640914686.0039005}
distributed.scheduler - INFO - Receive client connection: Client-4e96a159-69da-11ec-be0d-2d523a50f584
distributed.core - INFO - Starting established connection
distributed.scheduler - INFO - Receive client connection: Client-4e9669fe-69da-11ec-8cdc-f98c9b6c9404
distributed.core - INFO - Starting established connection
distributed.utils_perf - INFO - full garbage collection released 71.91 MB from 1574 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 38.30 MB from 1203 reference cycles (threshold: 10.00 MB)
distributed.utils_perf - INFO - full garbage collection released 80.24 MB from 910 reference cycles (threshold: 10.00 MB)
distributed.scheduler - INFO - Remove client Client-4e96a159-69da-11ec-be0d-2d523a50f584
distributed.scheduler - INFO - Remove client Client-4e96a159-69da-11ec-be0d-2d523a50f584
distributed.scheduler - INFO - Close client connection: Client-4e96a159-69da-11ec-be0d-2d523a50f584
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:46447', name: 10, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:46447
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:44289', name: 6, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:44289
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:40943', name: 4, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:40943
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:43817', name: 24, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:43817
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:41189', name: 39, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:41189
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:46745', name: 38, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:46745
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:36767', name: 26, memory: 1, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:36767
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:34247', name: 25, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:34247
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:38513', name: 23, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:38513
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:46421', name: 54, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:46421
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:46807', name: 53, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:46807
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:37935', name: 19, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:37935
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:34381', name: 28, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:34381
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:38639', name: 60, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:38639
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:44377', name: 18, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:44377
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:39743', name: 29, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:39743
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:33905', name: 34, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:33905
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:45321', name: 64, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:45321
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:43473', name: 40, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:43473
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:43059', name: 44, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:43059
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:34903', name: 62, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:34903
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:33457', name: 33, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:33457
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:34779', name: 30, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:34779
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.38:36301', name: 31, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.38:36301
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:40633', name: 52, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:40633
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:39883', name: 7, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:39883
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:38689', name: 42, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:38689
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:36835', name: 16, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:36835
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:33761', name: 15, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:33761
distributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:39307', name: 45, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:39307
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:33821', name: 12, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:33821
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:37983', name: 43, memory: 0, processing: 3>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:37983
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:36499', name: 1, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:36499
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:37175', name: 2, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:37175
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:45327', name: 9, memory: 0, processing: 3>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:45327
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:46789', name: 56, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:46789
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.37:36143', name: 8, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.37:36143
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:36627', name: 47, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:36627
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:45913', name: 46, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:45913
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:33319', name: 48, memory: 0, processing: 3>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:33319
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:33349', name: 37, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:33349
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:46199', name: 63, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:46199
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.39:35187', name: 41, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.39:35187
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:35513', name: 51, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:35513
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:43813', name: 55, memory: 0, processing: 3>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:43813
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:34657', name: 65, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:34657
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:41837', name: 57, memory: 0, processing: 4>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:41837
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:43867', name: 59, memory: 0, processing: 1>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:43867
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.8.40:35369', name: 67, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.8.40:35369
slurmstepd: error: *** STEP 52450237.0 ON nid01401 CANCELLED AT 2021-12-31T03:37:55 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 52450237 ON nid01401 CANCELLED AT 2021-12-31T03:37:55 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.128.5.134:38487', name: 50, memory: 0, processing: 2>
distributed.core - INFO - Removing comms to tcp://10.128.5.134:38487
srun: got SIGCONT
srun: forcing job termination
